{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "beneficial-neutral",
   "metadata": {},
   "source": [
    "# Generative Adversarial Network\n",
    "by Búgvi Benjamin Magnussen and Nikolaj Bläser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "strange-effort",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opposed-reception",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Swap this boolean to choose between convolutional networks and dense (maxout) networks\n",
    "use_convolutions = True\n",
    "tf.config.experimental.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unlike-bulletin",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "metallic-discretion",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist.load_data()\n",
    "(X_train, y_train), (X_test, y_test) = mnist\n",
    "y_train = tf.keras.utils.to_categorical(y_train)\n",
    "y_test = tf.keras.utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "absolute-hopkins",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(images):\n",
    "  return (images - 127.5) / 127.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hearing-district",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = normalize(X_train)\n",
    "X_test = normalize(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "armed-athletics",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = X_train[0]\n",
    "plt.imshow(image, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "civil-found",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_WIDTH = image.shape[0]\n",
    "IMAGE_HEIGHT = image.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "noticed-pierce",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 256\n",
    "X_train = tf.data.Dataset.from_tensor_slices(X_train).shuffle(len(X_train)).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "consolidated-memphis",
   "metadata": {},
   "source": [
    "# Activation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "artistic-clear",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The code is from tensorflow.contrib.layers.maxout\n",
    "def maxout(inputs, num_units, axis=-1):\n",
    "  '''\n",
    "  inputs: Tensor input\n",
    "  num_units: The num of unit keeped after amxout\n",
    "  axis: The dimension max op performed\n",
    "  scope: Optional scope for variable_scope\n",
    "     Note: This is a slightly modified version. Replaced some unused API functions\n",
    "  '''\n",
    "  shape = inputs.get_shape().as_list()\n",
    "  num_channels = shape[axis]\n",
    "  if num_channels % num_units:\n",
    "    raise ValueError('number of features({}) is not '\n",
    "                      'a multiple of num_units({})'.format(\n",
    "                          num_channels, num_units))\n",
    "  shape[axis] = -1\n",
    "  shape += [num_channels // num_units]\n",
    "\n",
    "  # Dealing with batches with arbitrary sizes\n",
    "  for i in range(len(shape)): # This is used to handle the case where None is included in the shape\n",
    "    if shape[i] is None:\n",
    "      shape[i] = tf.shape(inputs)[i]\n",
    "  outputs = tf.reduce_max( tf.reshape(inputs, shape), -1)\n",
    "  return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "federal-advocacy",
   "metadata": {},
   "source": [
    "# Layer Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "animated-toronto",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def denseRelu(inputs, weights, bias):\n",
    "  return tf.nn.relu(tf.nn.bias_add(tf.matmul(inputs, weights), bias))\n",
    "\n",
    "def denseLeakyRelu(inputs, weights, bias):\n",
    "  return tf.nn.leaky_relu(tf.nn.bias_add(tf.matmul(inputs, weights), bias))\n",
    "\n",
    "def denseTanh(inputs, weights, bias):\n",
    "  return tf.nn.tanh(tf.nn.bias_add(tf.matmul(inputs, weights), bias))\n",
    "\n",
    "def denseSigmoid(inputs, weights, bias):\n",
    "  return tf.nn.sigmoid(tf.nn.bias_add(tf.matmul(inputs, weights), bias))\n",
    "\n",
    "\n",
    "def denseMaxout(inputs, weights, bias, num_of_units=2, dropout_rate=0.5):\n",
    "  z = tf.nn.bias_add(tf.matmul(inputs, weights), bias)\n",
    "  z_dropout = tf.nn.dropout(z, rate=dropout_rate)\n",
    "  return maxout(z_dropout, num_of_units)\n",
    "\n",
    "def conv2dLeakyRelu(inputs, filters, channels, width, height, stride_size, dropout_rate=0.3):\n",
    "  inputs = tf.reshape(inputs, [-1, width, height, channels])\n",
    "  z = tf.nn.leaky_relu(tf.nn.conv2d(inputs, filters, [stride_size, stride_size], padding='SAME'))\n",
    "  out = tf.nn.dropout(z, rate=dropout_rate)\n",
    "  return out\n",
    "\n",
    "def conv2d_transpose(inputs, filters, channels, width, height, output_shape, stride_size):\n",
    "  inputs = tf.reshape(inputs, [-1, width, height, channels])\n",
    "  out = tf.nn.conv2d_transpose(inputs, filters, output_shape=output_shape, strides=[1, stride_size, stride_size, 1]) #padding is same\n",
    "  return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "seasonal-market",
   "metadata": {},
   "source": [
    "# Parameter Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "disturbed-citizenship",
   "metadata": {},
   "outputs": [],
   "source": [
    "initializer = tf.initializers.glorot_normal()\n",
    "bias_initializer = tf.initializers.zeros()\n",
    "\n",
    "def get_biases(n_units, name):\n",
    "  return tf.Variable(bias_initializer(n_units, dtype=tf.float32), name = name, trainable = True, dtype=tf.float32)\n",
    "\n",
    "def get_weights(shape, name):\n",
    "  return tf.Variable(initializer(shape, dtype=tf.float32), name = name, trainable = True, dtype=tf.float32)\n",
    "\n",
    "def get_filters(shape, name):\n",
    "  return tf.Variable(initializer(shape, dtype=tf.float32), name = name, trainable = True, dtype=tf.float32)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "secondary-mustang",
   "metadata": {},
   "source": [
    "# Discriminator - Maxout Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "empirical-green",
   "metadata": {},
   "outputs": [],
   "source": [
    "if (not use_convolutions):\n",
    "  discriminator_biases = [\n",
    "    get_biases(1024, 'bias0'),\n",
    "    get_biases(512, 'bias1'),\n",
    "    get_biases(1, 'bias2')\n",
    "  ]\n",
    "\n",
    "  discriminator_weights = [\n",
    "    get_weights([image.shape[0] * image.shape[1], 1024], 'weights0'),\n",
    "    get_weights([256, 512], 'weights1'),\n",
    "    get_weights([256, 1], 'weights2'),\n",
    "  ]\n",
    "\n",
    "  discriminator_parameters = discriminator_weights + discriminator_biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "careful-company",
   "metadata": {},
   "outputs": [],
   "source": [
    "if(not use_convolutions):\n",
    "  dropout_rate = 0.5\n",
    "\n",
    "  @tf.function\n",
    "  def discriminator(x):\n",
    "    x = tf.cast(x, dtype=tf.float32)\n",
    "    x = tf.reshape(x, shape=[x.shape[0], x.shape[1] * x.shape[2]])\n",
    "    d1 = denseMaxout(x, discriminator_weights[0], discriminator_biases[0], num_of_units=256, dropout_rate=dropout_rate)\n",
    "    d2 = denseMaxout(d1, discriminator_weights[1], discriminator_biases[1], num_of_units=256, dropout_rate=dropout_rate)\n",
    "    return denseSigmoid(d2, discriminator_weights[2], discriminator_biases[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pointed-setup",
   "metadata": {},
   "source": [
    "# Generator - Dense Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "valued-kingdom",
   "metadata": {},
   "outputs": [],
   "source": [
    "if(not use_convolutions):\n",
    "  generator_biases = [\n",
    "    get_biases(256, 'bias0'),\n",
    "    get_biases(512, 'bias1'),\n",
    "    get_biases(1024, 'bias2'),\n",
    "    get_biases(image.shape[0] * image.shape[1], 'bias3')\n",
    "  ]\n",
    "\n",
    "  generator_weights = [\n",
    "    get_weights([100, 256], 'weights0'),\n",
    "    get_weights([256, 512], 'weights1'),\n",
    "    get_weights([512, 1024], 'weights2'),\n",
    "    get_weights([1024, image.shape[0] * image.shape[1]], 'weights3')\n",
    "  ]\n",
    "\n",
    "  generator_parameters = generator_weights + generator_biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "appropriate-folks",
   "metadata": {},
   "outputs": [],
   "source": [
    "if(not use_convolutions):\n",
    "  @tf.function\n",
    "  def generator(x):\n",
    "    x = tf.cast(x, dtype=tf.float32)\n",
    "    d1 = denseLeakyRelu(x, generator_weights[0], generator_biases[0])\n",
    "    d2 = denseLeakyRelu(d1, generator_weights[1], generator_biases[1])\n",
    "    d3 = denseLeakyRelu(d2, generator_weights[2], generator_biases[2])\n",
    "    output = denseTanh(d3, generator_weights[3], generator_biases[3])\n",
    "    return tf.reshape(output, [x.shape[0], IMAGE_WIDTH, IMAGE_HEIGHT])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "charitable-allah",
   "metadata": {},
   "source": [
    "# Discriminator - Convolutional Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arranged-spell",
   "metadata": {},
   "outputs": [],
   "source": [
    "if(use_convolutions):\n",
    "  discriminator_biases = [\n",
    "\n",
    "  ]\n",
    "\n",
    "  discriminator_weights = [\n",
    "    get_filters([5, 5, 1, 64], 'filters1'),\n",
    "    get_filters([5, 5, 64, 128], 'filters2'),\n",
    "    get_weights([7*7*128, 1], 'weights0') \n",
    "  ]\n",
    "\n",
    "  discriminator_parameters = discriminator_weights + discriminator_biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "honest-recording",
   "metadata": {},
   "outputs": [],
   "source": [
    "if(use_convolutions):\n",
    "  dropout_rate = 0.3\n",
    "\n",
    "  @tf.function\n",
    "  def discriminator(x):\n",
    "    batchsize = x.shape[0]\n",
    "    x = tf.cast(x, dtype=tf.float32)\n",
    "    d1 = conv2dLeakyRelu(x, discriminator_weights[0], channels=1, width=28, height=28, stride_size=2, dropout_rate=dropout_rate)\n",
    "    d2 = conv2dLeakyRelu(d1, discriminator_weights[1], channels=64, width=14, height=14, stride_size=2, dropout_rate=dropout_rate)\n",
    "    d2 = tf.reshape(d2, [batchsize, -1])\n",
    "    return tf.nn.sigmoid(tf.matmul(d2, discriminator_weights[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bacterial-accordance",
   "metadata": {},
   "source": [
    "# Generator - Convolutional Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regional-civilian",
   "metadata": {},
   "outputs": [],
   "source": [
    "if(use_convolutions):\n",
    "  generator_biases = [\n",
    "  ]\n",
    "\n",
    "  generator_weights = [\n",
    "    get_weights([100, 7*7*256], 'weights0'),\n",
    "    get_filters([5, 5, 128, 256], 'filters1'),      \n",
    "    get_filters([5, 5, 64, 128], 'filters0'),\n",
    "    get_filters([5, 5, 1, 64], 'filters1')   \n",
    "  ]\n",
    "\n",
    "  generator_parameters = generator_weights + generator_biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "headed-placement",
   "metadata": {},
   "outputs": [],
   "source": [
    "if(use_convolutions):\n",
    "  @tf.function\n",
    "  def generator(x):\n",
    "    x = tf.cast(x, dtype=tf.float32)\n",
    "    d1 = tf.nn.leaky_relu(tf.matmul(x, generator_weights[0]))\n",
    "    d2 = tf.nn.leaky_relu(conv2d_transpose(inputs=d1, filters=generator_weights[1], channels=256, width=7, height=7, output_shape=(d1.shape[0], 7, 7, 128), stride_size=1))\n",
    "    d3 = tf.nn.leaky_relu(conv2d_transpose(inputs=d2, filters=generator_weights[2], channels=128, width=7, height=7, output_shape=(d2.shape[0], 14, 14, 64), stride_size=2))\n",
    "    output = tf.nn.tanh(conv2d_transpose(inputs=d3, filters=generator_weights[3], channels=64, width=14, height=14, output_shape=(d3.shape[0], 28, 28, 1), stride_size=2))\n",
    "    return tf.reshape(output, [x.shape[0], IMAGE_WIDTH, IMAGE_HEIGHT])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "uniform-advisory",
   "metadata": {},
   "source": [
    "# Generated Image Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collaborative-hacker",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_image(input):\n",
    "  gen_img = generator(input)\n",
    "  f, ax = plt.subplots(1,4, figsize=(12, 48))\n",
    "  ax[0].imshow((gen_img[0]) , cmap='gray')\n",
    "  ax[1].imshow((gen_img[1]) , cmap='gray')\n",
    "  ax[2].imshow((gen_img[2]) , cmap='gray')\n",
    "  ax[3].imshow((gen_img[3]) , cmap='gray')\n",
    "  plt.pause(0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "included-vitamin",
   "metadata": {},
   "source": [
    "# Loss Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "republican-spider",
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_loss(real_output, fake_output):\n",
    "    assert len(real_output) == len(fake_output)\n",
    "    return tf.math.reduce_mean(tf.math.reduce_sum(tf.math.log(real_output) + tf.math.log(1 - fake_output)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "otherwise-junior",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_loss(fake_output):\n",
    "    return tf.math.reduce_mean(tf.math.reduce_sum(tf.math.log(1 - fake_output)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "southern-fantasy",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_optimizer = tf.keras.optimizers.Adam(4e-5, beta_1=0.9)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(-1e-4, beta_1=0.9) # negative because we want to maximise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cutting-fourth",
   "metadata": {},
   "source": [
    "# Inception Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "guilty-fishing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source: https://machinelearningmastery.com/how-to-implement-the-inception-score-from-scratch-for-evaluating-generated-images/\n",
    "# calculate the inception score for p(y|x)\n",
    "def calculate_inception_score(p_yx, eps=1E-16):\n",
    "  # calculate p(y)\n",
    "  p_y = np.expand_dims(p_yx.mean(axis=0), 0)\n",
    "  # kl divergence for each image\n",
    "  kl_d = p_yx * (np.log(p_yx + eps) - np.log(p_y + eps))\n",
    "  # sum over classes\n",
    "  sum_kl_d = kl_d.sum(axis=1)\n",
    "  # average over images\n",
    "  avg_kl_d = np.mean(sum_kl_d)\n",
    "  # undo the logs\n",
    "  is_score = np.exp(avg_kl_d)\n",
    "  return is_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "twenty-xerox",
   "metadata": {},
   "source": [
    "# Loading pretrained classifier weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "associate-taylor",
   "metadata": {},
   "outputs": [],
   "source": [
    "np_weights = np.load('./Classifier_params/weights.npy', allow_pickle=True)\n",
    "np_biases = np.load('./classifier_params/biases.npy', allow_pickle=True)\n",
    "classifier_weights = [tf.Variable(w, trainable = True, dtype=tf.float64) for w in np_weights]\n",
    "classifier_biases = [tf.Variable(w, trainable = True, dtype=tf.float64) for w in np_biases]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prerequisite-sequence",
   "metadata": {},
   "source": [
    "# Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "focal-found",
   "metadata": {},
   "outputs": [],
   "source": [
    "dropout_rate = 0.5\n",
    "\n",
    "@tf.function\n",
    "def classifier(x):\n",
    "  x = tf.cast(x, dtype=tf.float64)\n",
    "  x = tf.reshape(x, shape=[x.shape[0], x.shape[1] * x.shape[2]])\n",
    "  d1 = denseMaxout(x, classifier_weights[0], classifier_biases[0], num_of_units=240, dropout_rate=dropout_rate)\n",
    "  d2 = denseMaxout(d1, classifier_weights[1], classifier_biases[1], num_of_units=240, dropout_rate=dropout_rate)\n",
    "  return tf.nn.softmax(tf.nn.bias_add(tf.matmul(d2, classifier_weights[2]), classifier_biases[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "threaded-rubber",
   "metadata": {},
   "source": [
    "# Inception Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "criminal-travel",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_inception_plot(epochs, input):\n",
    "  plt.plot(epochs, input)\n",
    "  plt.xlabel('Epochs')\n",
    "  plt.ylabel('Inception Score')\n",
    "  plt.pause(0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "controlled-practice",
   "metadata": {},
   "source": [
    "# Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "green-islam",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 500\n",
    "K = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "flexible-boutique",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "scheduled-manual",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(real_images, index):\n",
    "  generated_images = generator(tf.random.normal(shape = [len(real_images), 100]))\n",
    "  with tf.GradientTape() as disc_tape:\n",
    "    real_output = discriminator(real_images)\n",
    "    fake_output = discriminator(generated_images)\n",
    "    \n",
    "    disc_loss = discriminator_loss(real_output, fake_output)\n",
    "  \n",
    "  gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator_parameters)\n",
    "  discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator_parameters))\n",
    "\n",
    "  if (index % K == 0):\n",
    "    with tf.GradientTape() as gen_tape:\n",
    "      generated_images = generator(tf.random.normal(shape = [BATCH_SIZE, 100]))\n",
    "      fake_output = discriminator(generated_images)\n",
    "      gen_loss = generator_loss(fake_output)\n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, generator_parameters)\n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator_parameters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stone-stewart",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "test_input = tf.random.normal([4, 100], seed=12345)\n",
    "# used for inception score\n",
    "inception_validation_input = tf.random.normal([10000, 100])\n",
    "inception_scores = [0] * EPOCHS\n",
    "epochs = list(range(0, EPOCHS))\n",
    "\n",
    "for e in range(EPOCHS):\n",
    "  clear_output(wait=True)\n",
    "  print(\"Epochs: \" + str(e+1) + \"\\\\\" + str(EPOCHS))\n",
    "  generate_image(test_input)\n",
    "  inception_scores[e] = calculate_inception_score(classifier(generator(inception_validation_input)).numpy())\n",
    "  generate_inception_plot(epochs, inception_scores)\n",
    "  plt.clf()\n",
    "  for index, real_images in enumerate(X_train):\n",
    "    train_step(real_images, index)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "regular-perth",
   "metadata": {},
   "source": [
    "# Inception Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incorrect-expansion",
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_classified_images = classifier(generator(tf.random.normal([10000, 100])))\n",
    "print(calculate_inception_score(generated_classified_images.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dynamic-contents",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow-GPU",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
